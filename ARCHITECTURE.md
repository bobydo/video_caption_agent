# ü§ñ AI Agent: Modular Architecture

## **Project Structure**

```
agent/
‚îú‚îÄ‚îÄ config.py                      ‚Üê All configuration in one place
‚îú‚îÄ‚îÄ auto_improve_subtitles.py      ‚Üê Main entry point (clean & simple)
‚îÇ
‚îú‚îÄ‚îÄ core/                          ‚Üê Graph infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ state.py                   ‚Üê GraphState data class
‚îÇ   ‚îú‚îÄ‚îÄ graph.py                   ‚Üê NodeType enum, EdgeConditions
‚îÇ   ‚îî‚îÄ‚îÄ resolver.py                ‚Üê Orchestrates graph execution
‚îÇ
‚îú‚îÄ‚îÄ nodes/                         ‚Üê Processing nodes (one class per file)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base_node.py               ‚Üê Abstract base class
‚îÇ   ‚îú‚îÄ‚îÄ analyze_target_node.py     ‚Üê Extract metrics from target
‚îÇ   ‚îú‚îÄ‚îÄ generate_video_node.py     ‚Üê Create video with subtitles
‚îÇ   ‚îú‚îÄ‚îÄ take_screenshot_node.py    ‚Üê Capture frame
‚îÇ   ‚îú‚îÄ‚îÄ analyze_current_node.py    ‚Üê OCR analysis
‚îÇ   ‚îú‚îÄ‚îÄ compare_node.py            ‚Üê Score comparison
‚îÇ   ‚îî‚îÄ‚îÄ adjust_parameters_node.py  ‚Üê Smart parameter tuning
‚îÇ
‚îú‚îÄ‚îÄ utils/                         ‚Üê Helper utilities
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ ocr_analyzer.py            ‚Üê EasyOCR wrapper class
‚îÇ   ‚îî‚îÄ‚îÄ subtitle_renderer.py       ‚Üê PIL rendering functions
‚îÇ
‚îú‚îÄ‚îÄ output/                        ‚Üê Generated videos
‚îú‚îÄ‚îÄ screenshots/                   ‚Üê Analysis screenshots
‚îÇ
‚îú‚îÄ‚îÄ chinese_sample.jpg             ‚Üê Reference image
‚îú‚îÄ‚îÄ 10_second.mp4                  ‚Üê Source video
‚îÇ
‚îú‚îÄ‚îÄ README.md                      ‚Üê This file
‚îî‚îÄ‚îÄ run_agent.bat                  ‚Üê Quick run script
```

## **Clean Architecture Benefits**

‚úÖ **Separated Concerns**: Each file has one clear responsibility  
‚úÖ **Easy to Test**: Each node/util can be tested independently  
‚úÖ **Easy to Extend**: Add new nodes without touching existing code  
‚úÖ **Configuration Centralized**: All settings in `config.py`  
‚úÖ **Class-Based**: Clean OOP design with inheritance  
‚úÖ **Modular**: Import only what you need  

## **Configuration**

All configuration is in **`config.py`**:

```python
config = AgentConfig(
    max_iterations=7,              # Stop after N tries
    success_threshold=95.0,        # Score needed to succeed
    comparison_weights={           # How to weight scores
        'clarity': 0.4,           # 40% OCR confidence
        'position': 0.3,          # 30% position match
        'size': 0.3               # 30% size match
    },
    font_size_range=[28, 30, 32, 34, 36, 38, 40],
    stroke_width_range=[1, 2, 3],
    position_range=[0.60, 0.63, 0.65, 0.67, 0.70]
)
```

## **How to Run**

```powershell
cd D:\video-agent\agent
python auto_improve_subtitles.py
```

or double-click `run_agent.bat`

## **File Responsibilities**

### **config.py**
- `AgentConfig`: All configurable parameters
- Validation logic for configuration

### **core/state.py**
- `GraphState`: Data that flows through nodes
- Tracks iteration, metrics, parameters, results

### **core/graph.py**
- `NodeType`: Enum of all node types
- `EdgeConditions`: Logic for graph transitions

### **core/resolver.py**
- `SubtitleResolver`: Orchestrates graph execution
- Manages node sequence and stop conditions
- Saves results and prints summary

### **nodes/base_node.py**
- `BaseNode`: Abstract base class
- Defines `execute()` interface

### **nodes/analyze_target_node.py**
- `AnalyzeTargetNode`: Analyzes reference image
- Extracts target metrics using OCR

### **nodes/generate_video_node.py**
- `GenerateVideoNode`: Creates video with subtitles
- Uses MoviePy and PIL rendering

### **nodes/take_screenshot_node.py**
- `TakeScreenshotNode`: Captures frame from video
- Saves screenshot for analysis

### **nodes/analyze_current_node.py**
- `AnalyzeCurrentNode`: OCR analysis of screenshot
- Extracts current metrics

### **nodes/compare_node.py**
- `CompareNode`: Scores current vs target
- Calculates clarity, position, size scores
- Tracks best result

### **nodes/adjust_parameters_node.py**
- `AdjustParametersNode`: Smart parameter tuning
- Adjusts based on comparison scores

### **utils/ocr_analyzer.py**
- `OCRAnalyzer`: Wrapper for EasyOCR
- Reusable OCR analysis logic

### **utils/subtitle_renderer.py**
- `create_subtitle_image()`: PIL-based subtitle rendering
- Pure function for image generation

## **Adding New Nodes**

1. Create new file in `nodes/`
2. Inherit from `BaseNode`
3. Implement `execute(state) -> state`
4. Add to `nodes/__init__.py`
5. Wire into resolver

Example:

```python
# nodes/my_new_node.py
from nodes.base_node import BaseNode
from core.state import GraphState

class MyNewNode(BaseNode):
    def execute(self, state: GraphState) -> GraphState:
        print("üÜï NODE: My New Node")
        # Your logic here
        return state
```

## **Modifying Configuration**

Edit `config.py` or pass custom config in `auto_improve_subtitles.py`:

```python
config = AgentConfig(
    max_iterations=10,          # Try more times
    success_threshold=90.0,     # Lower threshold
    comparison_weights={
        'clarity': 0.5,         # More weight on clarity
        'position': 0.25,
        'size': 0.25
    }
)
```

## **Debugging**

Each node prints its execution:
```
============================================================
üì∏ NODE: Analyze Target Image
============================================================
  üìù Detected: '...' (confidence: 94.32%)
  ‚úÖ Target Metrics Extracted
```

Check logs to see which node is executing and what it's doing.

## **Testing Individual Components**

```python
# Test OCR analyzer alone
from utils.ocr_analyzer import OCRAnalyzer
analyzer = OCRAnalyzer()
metrics = analyzer.analyze_image(Path("test.jpg"))

# Test subtitle renderer alone
from utils.subtitle_renderer import create_subtitle_image
img = create_subtitle_image("ÊµãËØï", 1920, 100, 32, 2, "font.ttc")

# Test single node
from nodes.analyze_target_node import AnalyzeTargetNode
node = AnalyzeTargetNode(target_path, analyzer)
new_state = node.execute(state)
```

## **Dependencies**

- **MoviePy**: Video processing
- **PIL/Pillow**: Image rendering
- **EasyOCR**: Chinese text detection
- **OpenCV**: Image operations

## **Key Concepts**

### **Node**
- Self-contained processing unit
- Takes state, returns state
- No side effects except logging

### **Edge**
- Conditional transition logic
- Determines when to continue/stop
- Implemented in `EdgeConditions` class

### **Resolver**
- Controls overall execution flow
- Manages node sequence
- Enforces stop conditions

### **State**
- Immutable data flow
- Passed between nodes
- Contains all context

---

**Clean, modular, maintainable code!** üéâ
