# ğŸ¤– AI Agent: Graph-Based Subtitle Improvement

An intelligent video subtitle optimization system that automatically generates Chinese subtitles and tunes font size and position to match a reference image (`chinese_sample.jpg`) using a graph-based node architecture.

## ğŸ¯ **Purpose**

This application fine-tunes Chinese subtitle appearance by:
- **Font Size Optimization**: Automatically adjusts subtitle font size to match target reference
- **Position Tuning**: Aligns subtitle vertical position with the reference image
- **Quality Assessment**: Uses OCR analysis to score clarity, position, and size accuracy

The system uses `chinese_sample.jpg` as the target reference to optimize subtitle rendering parameters through iterative improvement cycles.

## ğŸš€ **Quick Start**

```bash
# Install dependencies
pip install -r requirements.txt

# Run the agent
python auto_improve_subtitles.py
```

**Prerequisites:**
- Ollama running with a compatible Local LLM model (llama3.2:3b or similar)
- Input files: `chinese_sample.jpg` (reference) and `10_second.mp4` (video source)
- Python 3.8+ with required packages

## âš™ï¸ **Configuration (config.py)**

The main tuning parameters are defined in `config.py`:

### **Core Parameters**
```python
max_iterations: int = 1              # Maximum optimization cycles
success_threshold: float = 95.0      # Score threshold to stop early (0-100%)
initial_font_scale: float = 0.35     # Starting font size (35% of detected size)
```

### **Parameter Ranges**
```python
font_size_range: [20, 24, 28, 32, 36, 40, 44, 48]     # Font sizes to test
stroke_width_range: [1, 2, 3]                          # Stroke widths to try
position_range: [0.60, 0.63, 0.65, 0.67, 0.70]       # Vertical positions (0-1)
```

### **Scoring Weights**
```python
comparison_weights: {
    'clarity': 0.4,      # 40% weight on OCR confidence
    'position': 0.3,     # 30% weight on position match  
    'size': 0.3          # 30% weight on size match
}
```

## ğŸ—ï¸ **Node-Based Architecture**

The application uses a single-agent pipeline with specialized nodes:

### **Core Process Flow**
```
START â†’ Analyze Target â†’ Generate Video â†’ Take Screenshot 
           â†“                                    â†“
     Target Metrics              Analyze Current â† OCR Analysis
           â†“                                    â†“
     Font Properties                      Compare Metrics
                                               â†“
                                    â”Œâ”€â”€â”€ Score â‰¥ 95% or No Chinese found  â†’ STOP
                                    â””â”€â”€â”€ Else â†’ Adjust Parameters â†’ LOOP
```

### **Node Structure**
```
nodes/
â”œâ”€â”€ base_node.py              # Abstract base class for all nodes
â”œâ”€â”€ analyze_target_node.py    # Extract metrics from chinese_sample.jpg
â”œâ”€â”€ generate_video_node.py    # Create video with current parameters
â”œâ”€â”€ take_screenshot_node.py   # Capture frame from generated video
â”œâ”€â”€ analyze_current_node.py   # OCR analysis of current screenshot
â”œâ”€â”€ compare_node.py           # Score comparison with target
â””â”€â”€ adjust_parameters_node.py # Smart parameter optimization
```

Each node inherits from `BaseNode` and implements:
- `execute(state)`: Main processing logic
- Input/output state management
- Error handling and logging

## ğŸ“ **Directory Structure**

### **Output Folders**

#### **`output/` Directory**
- **`10_second_1.mp4`**, **`10_second_2.mp4`**, etc. - Generated videos for each iteration
- **`iteration_results.json`** - Complete results data including:
  - Parameter configurations tested
  - Scoring metrics for each iteration
  - Best performing parameters
  - Execution timestamps and performance data

#### **`screenshots/` Directory** 
- **`iteration_1_screenshot.png`**, **`iteration_2_screenshot.png`**, etc.
- Screenshots captured from each generated video for OCR analysis
- Used for comparing current results with target reference image
- Helps visualize subtitle positioning and clarity improvements

### **Core Files**
```
â”œâ”€â”€ auto_improve_subtitles.py    # Main execution script
â”œâ”€â”€ config.py                    # All configuration parameters
â”œâ”€â”€ chinese_sample.jpg           # Target reference image
â”œâ”€â”€ 10_second.mp4               # Source video file
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ core/                       # Graph state management
â”‚   â”œâ”€â”€ state.py                # GraphState class definition
â”‚   â”œâ”€â”€ graph.py                # Node execution graph
â”‚   â””â”€â”€ resolver.py             # Main execution resolver
â””â”€â”€ utils/                      # Helper utilities
    â”œâ”€â”€ ocr_analyzer.py         # EasyOCR integration
    â”œâ”€â”€ subtitle_renderer.py    # Video subtitle generation
    â”œâ”€â”€ whisper_tools.py        # Audio transcription
    â””â”€â”€ translate_tools.py      # Text translation
```

## ğŸ”„ **Process Loop**

### **Basic Workflow**
1. **Audio Processing**: Extract and transcribe audio using Whisper
2. **Translation**: Convert English text to Chinese using Ollama LLM
3. **Target Analysis**: Analyze `chinese_sample.jpg` to extract reference metrics
4. **Iterative Optimization**:
   - Generate video with current parameters
   - Take screenshot of result
   - Analyze current subtitle properties with OCR
   - Compare against target metrics (clarity, position, size)
   - Calculate composite score (weighted average)
   - If score < threshold: adjust parameters and repeat
   - If score â‰¥ threshold or max iterations reached: stop

### **Scoring System**
- **Clarity Score**: Based on OCR confidence of Chinese text recognition
- **Position Score**: Vertical position match with reference image
- **Size Score**: Font size similarity to target reference
- **Overall Score**: Weighted combination (configurable in `config.py`)

## ğŸ›‘ **Stop Conditions**

The optimization loop terminates when:
1. **Success Threshold Reached**: Score â‰¥ configured threshold (default: 95%)
2. **Max Iterations**: Reached iteration limit (default: 1, configurable)
3. **No Chinese Text**: OCR fails to detect Chinese characters in result
4. **Critical Error**: File I/O errors or processing failures

## ğŸ”§ **Technical Details**

### **Dependencies**
- **faster-whisper**: Audio transcription
- **easyocr**: Optical character recognition
- **opencv-python**: Image processing
- **moviepy**: Video generation and editing
- **ollama**: Local LLM integration
- **requests**: API communication

### **Supported Formats**
- **Input Video**: MP4, AVI, MOV (any format supported by moviepy)
- **Reference Image**: JPG, PNG (processed by EasyOCR)
- **Output Video**: MP4 with embedded subtitles

### **Future Enhancements**
The current implementation is a single-agent pipeline. Future versions may implement:
- **Multi-Agent Architecture**: Using LangGraph message-based state management
- **Parallel Parameter Testing**: Concurrent optimization paths
- **Advanced Scoring**: Machine learning-based quality assessment

```python
# Future multi-agent state structure
class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]
```